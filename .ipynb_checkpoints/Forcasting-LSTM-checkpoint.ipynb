{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d8315afd07bc0251a225deb67cca33c72fec349c"
   },
   "source": [
    "# Forcasting Demand-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bc5a117d1906dfc16c479829e08b2be250965b2b"
   },
   "source": [
    "* Importing required labraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"365f1fa4-7fde-43a2-abac-54701751c1fd\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"365f1fa4-7fde-43a2-abac-54701751c1fd\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"365f1fa4-7fde-43a2-abac-54701751c1fd\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '365f1fa4-7fde-43a2-abac-54701751c1fd' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.13.0.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"365f1fa4-7fde-43a2-abac-54701751c1fd\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"365f1fa4-7fde-43a2-abac-54701751c1fd\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"365f1fa4-7fde-43a2-abac-54701751c1fd\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '365f1fa4-7fde-43a2-abac-54701751c1fd' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.13.0.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"365f1fa4-7fde-43a2-abac-54701751c1fd\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import bokeh\n",
    "from bokeh.io import show\n",
    "from bokeh.models import CustomJS, ColumnDataSource, Slider, Label, Div, HoverTool, Band, Span, BoxAnnotation\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.palettes import Spectral11\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import re\n",
    "import statsmodels\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "import statsmodels.api as sm\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, LSTM\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "# from keras.layers import RepeatVector\n",
    "# from keras.layers import TimeDistributed\n",
    "# from keras.layers.convolutional import Conv1D\n",
    "# from keras.layers.convolutional import MaxPooling1D\n",
    "# from keras.layers import Flatten\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', module='matplotlib')\n",
    "bokeh.io.output_notebook()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f2a63faa7b3f65d8a3524931e06485bb29e509c1"
   },
   "source": [
    "* Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('../input/train.csv',parse_dates=['date'])\n",
    "df_train.sales = df_train.sales.astype(np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7e6af983648ee3683fba644736a7726876272274"
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f94fc6ac42194e61beb0a7eae94fdccaf6259a0e"
   },
   "source": [
    "getting idea abot the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5058dece8ffb7d12279a400b284b3a722911da78"
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bf3ac57a18635fc665508df3a9fa4048513c7607"
   },
   "source": [
    "* Check for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e166267c728cf72dfb7fd8e36e582a779c5fa2ac"
   },
   "outputs": [],
   "source": [
    "print(df_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5491a29cd3587d89da2875a85509636d23877b2a"
   },
   "source": [
    "* **Plot Data**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0a2568674afeb5275cd6c7a632f6aea90af9994e"
   },
   "source": [
    "Let's plot sales time series to get some general ideas about the data. The data is averaged (weekly) to make plots more readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "358327c59562fee6db361608895f6619bf730e7d"
   },
   "outputs": [],
   "source": [
    "i1, i2 = '1_1', '2_1'\n",
    "df_train['it_sa'] = df_train.item.astype(str) + '_' + df_train.store.astype(str) \n",
    "sales = df_train.pivot(index='date', columns='it_sa', values='sales').resample('W').mean()\n",
    "df_train.drop(columns=['it_sa'], inplace=True)\n",
    "# display(sales_w.head(3))\n",
    "sales_source = sales.loc[:, [i1, i2]].copy()\n",
    "source = ColumnDataSource(data=sales_source)\n",
    "source_ref = ColumnDataSource(data=sales)\n",
    "p1 = figure(plot_width=750, plot_height=150, title=i1, x_axis_type='datetime', tools=\"pan,wheel_zoom,reset\")\n",
    "line1 = p1.line(x='date', y=i1, source=source)\n",
    "p2 = figure(plot_width=750, plot_height=150, title=i2, x_axis_type='datetime', tools=p1.tools,\n",
    "            x_range=p1.x_range)\n",
    "line2 = p2.line('date', i2, source=source)\n",
    "p1.add_tools(HoverTool(tooltips=[('sales', '@{}'.format(i1)), ('vs.', '@{}'.format(i2))], \n",
    "                       renderers=[line1, line2], mode='vline'))\n",
    "p2.add_tools(HoverTool(tooltips=[('sales', '@{}'.format(i2)), ('vs.', '@{}'.format(i1))], \n",
    "                       renderers=[line1, line2], mode='vline'))\n",
    "\n",
    "slider_it1 = Slider(start=1, end=50, value=1, step=1, title=\"item a\", callback_policy=\"mouseup\")\n",
    "slider_it2 = Slider(start=1, end=50, value=1, step=1, title=\"item b\")\n",
    "slider_sa1 = Slider(start=1, end=10, value=1, step=1, title=\"store a\")\n",
    "slider_sa2 = Slider(start=1, end=10, value=1, step=1, title=\"store b\")\n",
    "js_code = \"\"\"\n",
    "    var v = cb_obj.value;\n",
    "    var y_old = source.data['{old}'];\n",
    "    var y_new = ref.data[{new}];\n",
    "    for (var i = 0; i < y_old.length; i++) {\n",
    "        y_old[i] = y_new[i];\n",
    "    }\n",
    "    source.change.emit();\n",
    "\"\"\"\n",
    "callback_it1 = CustomJS(args=dict(source=source, ref=source_ref, s=slider_sa1), code=js_code.replace('{old}', i1).replace('{new}', 'v + \"_\" + s.value'))\n",
    "callback_it2 = CustomJS(args=dict(source=source, ref=source_ref, s=slider_sa2), code=js_code.replace('{old}', i2).replace('{new}', 'v + \"_\" + s.value'))\n",
    "callback_sa1 = CustomJS(args=dict(source=source, ref=source_ref, s=slider_it1), code=js_code.replace('{old}', i1).replace('{new}', 's.value + \"_\" + v'))\n",
    "callback_sa2 = CustomJS(args=dict(source=source, ref=source_ref, s=slider_it2), code=js_code.replace('{old}', i2).replace('{new}', 's.value + \"_\" + v'))\n",
    "slider_it1.js_on_change('value', callback_it1)\n",
    "slider_it2.js_on_change('value', callback_it2)\n",
    "slider_sa1.js_on_change('value', callback_sa1)\n",
    "slider_sa2.js_on_change('value', callback_sa2)\n",
    "\n",
    "layout = bokeh.layouts.column(Div(text='<h4>Sales Volumes TS (Bokeh)</h4>'),\n",
    "                              bokeh.layouts.row(slider_it1, slider_sa1), p1, \n",
    "                              bokeh.layouts.row(slider_it2, slider_sa2), p2)\n",
    "bokeh.io.show(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7f37dd094e38be21fb9b34a9fa3450b1ff46aa01"
   },
   "source": [
    "* There is a clear Seasionality and trend in all the items and stores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fd74cc3ccaa3e8156d1f9567b1b4ac91ae62e6be"
   },
   "source": [
    "# Trend and Seasionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3b6267abd3ccde0b78080296b47d7d3341d82c76"
   },
   "source": [
    "* Adding Year,Month,Day,Day of week, Day of year and week of year as feature to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f252f60a1719839060eb60d5d826f1d967df4257"
   },
   "outputs": [],
   "source": [
    "def add_datepart(df, fldname, inplace=False, drop=False):\n",
    "    if not inplace: df = df.copy()        \n",
    "    fld = df[fldname]\n",
    "    fld_dtype = fld.dtype\n",
    "    if isinstance(fld_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n",
    "        fld_dtype = np.datetime64\n",
    "    if not np.issubdtype(fld_dtype, np.datetime64):\n",
    "        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n",
    "    targ_pre = re.sub('[Dd]ate$', '', fldname)\n",
    "    \n",
    "    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear','Weekofyear']\n",
    "\n",
    "    for n in attr: \n",
    "        df[targ_pre + n] = getattr(fld.dt, n.lower())\n",
    "    if drop: \n",
    "        df.drop(fldname, axis=1, inplace=True)\n",
    "    if not inplace: return df \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f1bc4aca28181656ac1c1c745bea5ef777b10b58"
   },
   "outputs": [],
   "source": [
    "df_trainext = add_datepart(df_train, 'date', inplace=False)\n",
    "display(df_trainext.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fc8710d52a11ef5b943af9360258c56ef77ec880"
   },
   "outputs": [],
   "source": [
    "df_trainext.groupby('date').mean()['sales'].plot(figsize=(12,3), title='Sales (aggregated data)')\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "_ = pd.pivot_table(df_trainext, values='sales', columns='Year', index='Month').plot(title=\"Yearly seasonality\", ax=ax[0,0])\n",
    "_ = pd.pivot_table(df_trainext, values='sales', columns='Month', index='Day').plot(title=\"Monthly seasonality\", ax=ax[0,1])\n",
    "_ = pd.pivot_table(df_trainext, values='sales', columns='Year', index='Dayofweek').plot(title=\"Weekly seasonality (by year)\", ax=ax[1,0])\n",
    "_ = pd.pivot_table(df_trainext, values='sales', columns='Month', index='Dayofweek').plot(title=\"Weekly seasonality (by month)\", ax=ax[1,1])\n",
    "fig.suptitle('Patern of Seasionality of Sales (aggregated data)')\n",
    "fig.tight_layout(rect=[0, 0, 1, 0.96])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d7cb7458daff41d0d95c469f62c0a66644c2e133"
   },
   "outputs": [],
   "source": [
    "_ = pd.pivot_table(df_trainext, values='sales', index='Year').plot(style='-o', title=\"Annual trend (aggregated data)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "66c3581fc8a6a72fc2e253c9d7a708624944f213"
   },
   "source": [
    " * **Seasonal Trend Decomposition** using **Loess (STL)** decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2d1ba397012a1a28d0eea6f34175e2a84a52096e"
   },
   "outputs": [],
   "source": [
    "freq_season_mapping = {'None':None, 'Weekly': 7, 'Monthly':30, 'Yearly':365}\n",
    "\n",
    "def update_stl_decompose(i_num, s_num, seasonality='Yearly', stl_style='additive'):\n",
    "    ts = df_train.query('store == @s_num & item == @i_num').set_index('date')['sales']\n",
    "    freq = freq_season_mapping[seasonality]\n",
    "    \n",
    "    fig, ax = plt.subplots(4, 1, figsize=(12,10))\n",
    "    decomposition = sm.tsa.seasonal_decompose(ts, model=stl_style, freq=freq)\n",
    "    _ = decomposition.observed.plot(ax=ax[0], title='observed')\n",
    "    _ = decomposition.trend.plot(ax=ax[1], title='trend')\n",
    "    _ = decomposition.seasonal.plot(ax=ax[2], title='seasonal')\n",
    "    _ = decomposition.resid.plot(ax=ax[3], title='residual')\n",
    "    res = decomposition.resid.values\n",
    "    res = res[np.isfinite(res)]\n",
    "# #     adfuller_stat = statsmodels.tsa.stattools.adfuller(res)\n",
    "#     ljungbox_stat = statsmodels.stats.diagnostic.acorr_ljungbox(res)\n",
    "#     statsmodels.graphics.tsaplots.plot_pacf(res, ax=ax[4], lags=40, \n",
    "#                                            title='residuals pacf; ljung-box p-value = {:.2E} / {:.2E}'.format(ljungbox_stat[1][6], \n",
    "#                                                                                                               ljungbox_stat[1][30]))\n",
    "    fig.suptitle('STL decomposition')\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    \n",
    "s_slider = widgets.IntSlider(min=1, max=10, continuous_update=False, description='store', layout={'width': '2.1in', 'height': '1in'})\n",
    "i_slider = widgets.IntSlider(min=1, max=50, continuous_update=False, description='item', layout={'width': '2.1in', 'height': '1in'})\n",
    "season_drop = widgets.Dropdown(value='Yearly', options=['Weekly', 'Monthly', 'Yearly'], description='seasonality', layout={'width': '2.1in'})\n",
    "stltype_drop = widgets.Dropdown(value='multiplicative', options=['additive', 'multiplicative'], description='STL type', layout={'width': '2.1in'})\n",
    "ui = widgets.HBox([s_slider, i_slider, season_drop, stltype_drop], layout={'min_width': '6in', 'max_width': '6in'})\n",
    "out = widgets.interactive_output(update_stl_decompose, {'s_num': s_slider, 'i_num': i_slider, \n",
    "                                                        'seasonality': season_drop, 'stl_style': stltype_drop})\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a3794bc73e35441f850b4b0dbf4cbe3c0eb2bc59"
   },
   "source": [
    "* Lag Auto-Correlation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "698f61ef97d69ab22341f06d951edcf27cefbcdf"
   },
   "outputs": [],
   "source": [
    "autocorrelation_plot(pd.pivot_table(df_trainext,values='sales',index='Day'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9d1395d853453eb5addaf3509da9d826fec95a2c"
   },
   "source": [
    "# Training Forecast Model by Encoder-Decoder LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "40c8f00d5c4f646ee50d1910743b08333731fc0a"
   },
   "outputs": [],
   "source": [
    "def split_dataset(data,hor=7):\n",
    "    # split into standard weeks\n",
    "    data=data.iloc[6:]\n",
    "    data_split=np.array(np.split(data.values, round(len(data)/hor)))\n",
    "    train,test=data_split[:248],data_split[248:]\n",
    "#     train, test = data.loc[:'2017-10-01'], data.loc['2017-10/-01':]\n",
    "    # restructure into windows of weekly data\n",
    "#     train = np.array(np.split(train.values, round(len(train)/hor)))\n",
    "#     test = np.array(np.split(test.values, round(len(test)/hor)))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "311f531f98f08f67c7a62aa95cc94473c1008bfd"
   },
   "outputs": [],
   "source": [
    "data_agg=pd.pivot_table(df_train,values='sales',index='date')\n",
    "train,test=split_dataset(data_agg,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8a47ce7801d37595a95c16935ecf107de5af3599"
   },
   "outputs": [],
   "source": [
    "# evaluate one or more weekly forecasts against expected values\n",
    "def evaluate_forecasts(actual, predicted):\n",
    "    scores = list()\n",
    "    # calculate an RMSE score for each day\n",
    "    for i in range(actual.shape[1]):\n",
    "        # calculate mse\n",
    "        mse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "        # calculate rmse\n",
    "        rmse = sqrt(mse)\n",
    "        # store\n",
    "        scores.append(rmse)\n",
    "    # calculate overall RMSE\n",
    "    s = 0\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            s += (actual[row, col] - predicted[row, col])**2\n",
    "    score = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "    return score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f1dbd2d3175711535ee4b091ce4204567a17bc07"
   },
   "outputs": [],
   "source": [
    "# evaluate a single model\n",
    "def evaluate_model(train, test, n_input):\n",
    "    # fit model\n",
    "    model = build_model(train, n_input)\n",
    "    # history is a list of weekly data\n",
    "    history = [x for x in train]\n",
    "    # walk-forward validation over each week\n",
    "    predictions = list()\n",
    "    for i in range(len(test)):\n",
    "        # predict the week\n",
    "        yhat_sequence = forecast(model, history, n_input)\n",
    "        # store the predictions\n",
    "        predictions.append(yhat_sequence)\n",
    "        # get real observation and add to history for predicting the next week\n",
    "        history.append(test[i, :])\n",
    "    # evaluate predictions days for each week\n",
    "    predictions = np.array(predictions)\n",
    "    score, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
    "    return score, scores,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5a108cf21f8b82b979375a7f85ae7d88078d7fdd"
   },
   "outputs": [],
   "source": [
    "# summarize scores\n",
    "def summarize_scores(name, score, scores):\n",
    "    s_scores = ', '.join(['%.1f' % s for s in scores])\n",
    "    print('%s: [%.3f] %s' % (name, score, s_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc1ad987b34532d672144337b14bf216a5b187a9"
   },
   "outputs": [],
   "source": [
    "# convert history into inputs and outputs\n",
    "def to_supervised(train, n_input, n_out=7):\n",
    "    # flatten data\n",
    "    data = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
    "    X, y = list(), list()\n",
    "    in_start = 0\n",
    "    # step over the entire history one time step at a time\n",
    "    for _ in range(len(data)):\n",
    "        # define the end of the input sequence\n",
    "        in_end = in_start + n_input\n",
    "        out_end = in_end + n_out\n",
    "        # ensure we have enough data for this instance\n",
    "        if out_end < len(data):\n",
    "            x_input = data[in_start:in_end, 0]\n",
    "            x_input = x_input.reshape((len(x_input), 1))\n",
    "            X.append(x_input)\n",
    "            y.append(data[in_end:out_end, 0])\n",
    "        # move along one time step\n",
    "        in_start += 1\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "78eb2c893a8520c633f47d1ad296b479493ef560"
   },
   "outputs": [],
   "source": [
    "# make a forecast\n",
    "def forecast(model, history, n_input):\n",
    "    # flatten data\n",
    "    data = np.array(history)\n",
    "    data = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "    # retrieve last observations for input data\n",
    "    input_x = data[-n_input:, 0]\n",
    "    # reshape into [1, n_input, 1]\n",
    "    input_x = input_x.reshape((1, len(input_x), 1))\n",
    "    # forecast the next week\n",
    "    yhat = model.predict(input_x, verbose=0)\n",
    "    # we only want the vector forecast\n",
    "    yhat = yhat[0]\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "976f28a55dab8e1d66303a390e09ad842d40b949"
   },
   "outputs": [],
   "source": [
    "def build_model(train, n_input):\n",
    "    # prepare data\n",
    "    train_x, train_y = to_supervised(train, n_input)\n",
    "    # define parameters\n",
    "    verbose, epochs, batch_size = 0, 25, 16\n",
    "    n_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
    "    # reshape output into [samples, timesteps, features]\n",
    "    train_y = train_y.reshape((train_y.shape[0], train_y.shape[1], 1))\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(300, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "    model.add(RepeatVector(n_outputs))\n",
    "    model.add(LSTM(300, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # fit network\n",
    "    model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c1ba098aa4af69a078a339d897af36cfe9a970c1"
   },
   "outputs": [],
   "source": [
    "# evaluate model and get scores\n",
    "n_input = 7\n",
    "score, scores,model = evaluate_model(train, test, n_input)\n",
    "# summarize scores\n",
    "summarize_scores('lstm', score, scores)\n",
    "# plot scores\n",
    "days = [ 'Sunday', 'Monday', 'Tuesday', 'Wednsday', 'Thursday', 'Friday','Saturday']\n",
    "plt.plot(days, scores, marker='o', label='lstm')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dedd1627859f7cc130972c6c654f7c454283c08b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
